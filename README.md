# Explainable-NER

Applying Layer-wise Relevance Propagation (LRP) to make Named Entity Recognition (NER) explainable. 
The NER model is implemented with Bi-directional LSTM (Bi-LSTM) and Conditional Random Field (CRF).

## Environment:

- Python 3.5
- Keras 2.1.5
- Sickit-learn 0.19.1
- Pandas 0.22.0
- Numpy 1.14.2
- Matplotlib 2.2.2

## Acknowledgments
[Explaining Recurrent Neural Network Predictions in Sentiment Analysis by Arras, Leila, et al, 2017](http://aclweb.org/anthology/W/W17/W17-5221.pdf)

[Explaining Recurrent Neural Network Predictions in Sentiment Analysis, code](https://github.com/ArrasL/LRP_for_LSTM)

[Explaining Recurrent Neural Network Predictions in Sentiment Analysis by L. Arras, G. Montavon, K.-R. MÃ¼ller and W. Samek, 2017](http://aclweb.org/anthology/W/W17/W17-5221.pdf)

[Visualizing and Understanding Neural Models in NLP by J. Li, X. Chen, E. Hovy and D. Jurafsky, 2016](https://arxiv.org/abs/1506.01066)

[Visualizing and understanding neural machine translation by Ding, Yanzhuo, et al. 2017](http://www.aclweb.org/anthology/P17-1106)



